from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.settings import Settings

# ğŸ“‚ AdÄ±m 1 â€“ Belgeleri oku
documents = SimpleDirectoryReader("data").load_data()

# âš™ï¸ AdÄ±m 2 â€“ Embedding & Index ayarÄ±
Settings.embed_model = HuggingFaceEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ§  AdÄ±m 3 â€“ Index oluÅŸtur
index = VectorStoreIndex.from_documents(documents)

# â“ AdÄ±m 4 â€“ Soru-cevap
query_engine = index.as_query_engine()
response = query_engine.query("Yapay zekÃ¢ saÄŸlÄ±k alanÄ±nda nasÄ±l kullanÄ±lÄ±r?")
print(response)
